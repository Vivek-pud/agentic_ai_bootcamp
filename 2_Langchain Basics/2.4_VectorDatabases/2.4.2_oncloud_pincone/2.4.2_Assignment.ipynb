{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713fed48",
   "metadata": {},
   "source": [
    "# second assisgnment is: take a multiple pdf with text,image,table\n",
    "1. fetch the data from pdf\n",
    "2. at lesat there should be 200 pages\n",
    "3. if chunking(use the sementic chunking technique) required do chunking and then embedding\n",
    "4. store it inside the vector database(use any of them 1. mongodb 2. astradb 3. opensearch 4.milvus) ## i have not discuss then you need to explore\n",
    "5. create a index with all three index machnism(Flat, HNSW, IVF) ## i have not discuss then you need to explore\n",
    "6. create a retriever pipeline\n",
    "7. check the retriever time(which one is fastet)\n",
    "8. print the accuray score of every similarity search\n",
    "9. perform the reranking either using BM25 or MMR ## i have not discuss then you need to explore\n",
    "10. then write a prompt template\n",
    "11. generte a oputput through llm\n",
    "12. render that output over the DOCx ## i have not discuss then you need to explore\n",
    "as a additional tip: you can follow rag playlist from my youtube\n",
    "\n",
    "after completing it keep it on your github and share that link on my  mail id:\n",
    "snshrivas3365@gmail.com\n",
    "\n",
    "and share the assignment in your community chat as well by tagging krish and sunny\n",
    "\n",
    "deadline is: till firday 9PM\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f985264a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "len (embeddings.embed_query(\"This is a test query to generate embeddings.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30dca26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
