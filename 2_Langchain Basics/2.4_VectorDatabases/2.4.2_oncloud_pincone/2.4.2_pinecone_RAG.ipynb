{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65159145",
   "metadata": {},
   "outputs": [],
   "source": [
    "len (embeddings.embed_query(\"This is a test query to generate embeddings.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone( api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc47136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec # Create a serverless spec\n",
    "index_name = \"vivek-test-index\"\n",
    "\n",
    "if not pc.has_index(index_name):    # Create the index if it does not exist \n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric=\"cosine\",  # Similarity metric\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac47698",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)  # Connect to the index\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687770f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_store.similarity_search(\"What is langchain\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},#additional info\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c865dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94951117",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_store.similarity_search(\"What is langchain\", k = 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c325e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd1ae8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='42d98e06-f495-4ab4-acac-47030512ce48', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdfc7200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='{context}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"{context}\"),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e844309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\",temperature=0.0, max_tokens=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85a5928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6577a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e668ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough() } |\n",
    "    prompt |\n",
    "    model |\n",
    "    parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d8768d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's awesome! I'm always excited to hear about new projects using my abilities. \\n\\nLangChain is a fantastic framework for building applications with large language models (LLMs) like me.  Think of it as a toolbox specifically designed to make working with LLMs easier and more powerful. \\n\\nHere's a breakdown of what makes LangChain so special:\\n\\n**Key Features:**\\n\\n* **Chains:** LangChain lets you string together multiple LLMs and other tools (like search engines, databases, APIs) into sophisticated workflows. Imagine asking a question that requires multiple steps to answer â€“ LangChain can handle that seamlessly.\\n* **Agents:**  You can create autonomous agents that can interact with the world. These agents can use LLMs to understand instructions, plan actions, and execute them using other tools.\\n* **Memory:** LangChain provides ways to give your applications a memory, so they can remember past interactions and context. This is crucial for building conversational AI that feels more natural.\\n* **Prompt Templates:**  It offers a way to structure your prompts to LLMs more effectively, leading to better and more consistent results.\\n* **Integration:** LangChain integrates well with popular LLMs (like me!), as well as other tools and libraries.\\n\\n**Why Use LangChain?**\\n\\n* **Simplifies Development:**  It takes care of a lot of the boilerplate code involved in working with LLMs, allowing you to focus on the core logic of your application.\\n* **Enhances Capabilities:**  By combining LLMs with other tools, LangChain unlocks powerful new possibilities for your applications.\\n* **Promotes Reusability:**  You can build reusable components and chains that can be easily incorporated into different projects.\\n\\n**Want to Learn More?**\\n\\nThe best way to understand LangChain is to dive into its documentation and examples: [https://python.langchain.com/](https://python.langchain.com/)\\n\\nI'm eager to hear about your project! What kind of exciting things are you building with LangChain?\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is langchain?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
