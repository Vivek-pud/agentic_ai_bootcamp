{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28426203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"How are you?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41561aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "len (embeddings.embed_query(\"Hello world\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"usa.txt\")\n",
    "docs = loader.load()\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c36295",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs=text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_string=[doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(new_docs,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=db.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fbd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"industrial growth of usa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e898660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic:str=Field(description=\"selected topic\")\n",
    "    Reasoning:str=Field(description='Reasoning behind topic selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"hi\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state=\"hi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state:AgentState):\n",
    "    \n",
    "    question=state[\"messages\"][-1]\n",
    "    \n",
    "    print(\"Question\",question)\n",
    "    \n",
    "    template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [USA,Not Related]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt= PromptTemplate(\n",
    "        template=template,\n",
    "        input_variable=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    chain= prompt | model | parser\n",
    "    \n",
    "    response = chain.invoke({\"question\":question})\n",
    "    \n",
    "    print(\"Parsed response:\", response)\n",
    "    \n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a0b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is a today weather?\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is a GDP of usa??\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_1(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state:AgentState):\n",
    "    print(\"-> ROUTER ->\")\n",
    "    \n",
    "    last_message=state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "    \n",
    "    if \"usa\" in last_message.lower():\n",
    "        return \"RAG Call\"\n",
    "    else:\n",
    "        return \"LLM Call\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b933c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Function\n",
    "def function_2(state:AgentState):\n",
    "    print(\"-> RAG Call ->\")\n",
    "    \n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "        \n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(state:AgentState):\n",
    "    print(\"-> LLM Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    # Normal LLM call\n",
    "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
    "    response = model.invoke(complete_query)\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "workflow=StateGraph(AgentState)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"Supervisor\",function_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe155bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"RAG\",function_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"LLM\",function_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"Supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"Supervisor\",\n",
    "    router,\n",
    "    {\n",
    "        \"RAG Call\": \"RAG\",\n",
    "        \"LLM Call\": \"LLM\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state:AgentState):\n",
    "    print(\"-> ROUTER ->\")\n",
    "    \n",
    "    last_message=state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "    \n",
    "    if \"usa\" in last_message.lower():\n",
    "        return \"RAG Call\"\n",
    "    else:\n",
    "        return \"LLM Call\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376625b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(\"RAG\",END)\n",
    "workflow.add_edge(\"LLM\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97611a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ad833",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"hi\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"what is a gdp of usa?\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bee86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"can you tell me the industrial growth of world's most powerful economy?\"]}\n",
    "result=app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569570af",
   "metadata": {},
   "source": [
    "Assignment:4\n",
    "1. you have to create one supervisor node.\n",
    "2. create one router function\n",
    "3. create three more node\n",
    "3.1 llm call (llm node)\n",
    "3.2 RAG (rag node)\n",
    "3.3 web crawler(fetch the info in realtime from internet)\n",
    "4. created one more node after this for validation for generated output --> explore the validation part how to do that\n",
    "5. if validation going to be failed in that case again go to supervioser node and then supervisor node will again decide what needs to be call next\n",
    "6. once the validation will pass then only generate the final output\n",
    "\n",
    "submission deadline till 9pm friday\n",
    "\n",
    "submission instruction:\n",
    "create your github repo and keep all the assisgnments over there(in that github repo)\n",
    "i will share one googleform in group after completing your assignment you can share the github link through that google form. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
