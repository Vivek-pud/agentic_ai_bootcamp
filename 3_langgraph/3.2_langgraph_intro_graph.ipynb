{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ac16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model=ChatGoogleGenerativeAI(model = 'gemini-1.5-flash')\n",
    "output=model.invoke(\"hi\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae04c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def function1(state: AgentState) -> AgentState:\n",
    "    state[\"output\"] = state[\"input\"] + \" from first function\"\n",
    "    state[\"step\"] = \"model\"  # optional, if you're using it for control flow\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78917479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(state: AgentState) -> AgentState:\n",
    "    state[\"output\"] = state[\"output\"] + \" Pudur from second function\"\n",
    "    state[\"step\"] = \"end\"  # optional\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de958b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Literal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c42cd942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "          # The input\n",
    "          input: str\n",
    "          # The generated output\n",
    "          output: str\n",
    "          # The current step (used for control flow)\n",
    "# Create the graph\n",
    "workflow1 = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "867d7167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17b230b39b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow1.add_node(\"fun1\",function1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4c16acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17b230b39b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow1.add_node(\"fun2\",function2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf4cecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17b230b39b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow1.add_edge(\"fun1\",\"fun2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fc303f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17b230b39b0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow1.set_entry_point(\"fun1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "673426f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17b230b39b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow1.set_finish_point(\"fun2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e7b6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48ff1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'vivek',\n",
       " 'output': 'vivek from first function Pudur from second function'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"input\":\"vivek\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e1a3fc",
   "metadata": {},
   "source": [
    "First function as LLM and second function as Token counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ffffd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"{context}\"),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\",temperature=0.0, max_tokens=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4abb05af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New Delhi**. \\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the capital of India?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ec7c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    step: Literal[\"enter\", \"model\", \"count_tokens\", \"end\"]\n",
    "    messages: list\n",
    "    token_count: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a935f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_function(state: AgentState) -> AgentState:\n",
    "    result = model.invoke(state[\"input\"])\n",
    "    state[\"output\"] = result.content\n",
    "    state[\"messages\"].append({\"role\": \"model\", \"content\": result.content})\n",
    "    state[\"step\"] = \"count_tokens\"\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d85d2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter_function(state: AgentState) -> AgentState:\n",
    "    # Very basic token counter â€“ can be replaced with tiktoken or tokenizer\n",
    "    token_count = len(state[\"output\"].split())\n",
    "    state[\"token_count\"] = token_count\n",
    "    state[\"step\"] = \"end\"\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73e40c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"llm_node\", llm_function)\n",
    "graph.add_node(\"token_counter\", token_counter_function)\n",
    "\n",
    "graph.add_edge(\"llm_node\", \"token_counter\")\n",
    "\n",
    "graph.set_entry_point(\"llm_node\")\n",
    "graph.set_finish_point(\"token_counter\")\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f45a079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Output: ## LangGraph: A Deep Dive into the World of Language Representation\n",
      "\n",
      "LangGraph is a powerful and innovative approach to representing language, moving beyond traditional word embeddings and venturing into a more nuanced understanding of linguistic relationships. \n",
      "\n",
      "**At its core, LangGraph constructs a graph where:**\n",
      "\n",
      "* **Nodes:** Represent individual words or subword units (like morphemes or characters).\n",
      "* **Edges:** Capture semantic and syntactic relationships between these words.\n",
      "\n",
      "This graph-based representation allows LangGraph to capture complex linguistic phenomena that are often overlooked by simpler embedding models.\n",
      "\n",
      "**Here's a detailed breakdown of LangGraph's key features and functionalities:**\n",
      "\n",
      "**1. Graph Construction:**\n",
      "\n",
      "* **Word Embeddings as Node Features:** LangGraph starts with pre-trained word embeddings (like Word2Vec or GloVe) to initialize the nodes with semantic information.\n",
      "* **Relationship Extraction:**  It then utilizes various techniques to extract relationships between words. This can include:\n",
      "    * **Co-occurrence Statistics:** Analyzing how frequently words appear together in a given corpus.\n",
      "    * **Dependency Parsing:** Leveraging syntactic information from parsed sentences to identify grammatical relationships.\n",
      "    * **Knowledge Graphs:** Integrating external knowledge bases to incorporate factual relationships between entities.\n",
      "\n",
      "**2. Graph Neural Networks (GNNs):**\n",
      "\n",
      "* **Node Embeddings:** LangGraph employs GNNs to learn richer, context-aware node embeddings. These embeddings capture not only the individual semantic meaning of a word but also its relationships with other words in the graph.\n",
      "* **Message Passing:** GNNs operate through a process called \"message passing,\" where information is exchanged between neighboring nodes in the graph. This iterative process allows the model to learn complex dependencies and hierarchical structures within the language.\n",
      "\n",
      "**3. Downstream Applications:**\n",
      "\n",
      "* **Text Classification:** LangGraph's rich node embeddings can be used to classify text into predefined categories with improved accuracy.\n",
      "* **Question Answering:** The graph structure allows for better understanding of question-answer relationships, leading to more precise answers.\n",
      "* **Natural Language Inference:** LangGraph can be used to determine the logical relationship between two sentences, such as entailment or contradiction.\n",
      "* **Text Summarization:** By identifying key relationships between words, LangGraph can help generate concise and informative summaries of longer texts.\n",
      "\n",
      "**Advantages of LangGraph:**\n",
      "\n",
      "* **Captures Complex Relationships:**  LangGraph goes beyond simple word associations and captures intricate semantic and syntactic connections.\n",
      "* **Contextualized Embeddings:** GNNs learn node embeddings that are sensitive to the context in which words appear.\n",
      "* **Scalability:** LangGraph can be applied to large-scale datasets and complex language tasks.\n",
      "\n",
      "**Limitations of LangGraph:**\n",
      "\n",
      "* **Computational Cost:** Training GNNs can be computationally expensive, especially for large graphs.\n",
      "* **Data Dependency:** The quality of the graph construction heavily relies on the quality and size of the training data.\n",
      "* **Interpretability:** While GNNs offer powerful representations, interpreting the learned relationships within the graph can be challenging.\n",
      "\n",
      "\n",
      "**Overall, LangGraph represents a significant advancement in language representation, offering a more comprehensive and nuanced understanding of how words relate to each other. Its graph-based approach opens up new possibilities for tackling complex natural language processing tasks.**\n",
      "\n",
      "Token Count: 472\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"input\": \"Explain what LangGraph is in very detailed terms.\",\n",
    "    \"output\": \"\",\n",
    "    \"step\": \"enter\",\n",
    "    \"messages\": [],\n",
    "    \"token_count\": 0\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "print(\"LLM Output:\", result[\"output\"])\n",
    "print(\"Token Count:\", result[\"token_count\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
